{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql as mdb\n",
    "%matplotlib inline\n",
    "import geocoder\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib \n",
    "import pickle\n",
    "import pymysql as mdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#need to pickle after each pool so i don't have to rerun if interrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pool schedules have changed. I need to rescrape schedule for each pool. This time I will note website quirks of each pool for furture updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swimming_pool</th>\n",
       "      <th>website_source</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asser Levy</td>\n",
       "      <td>http://www.nycgovparks.org/facilities/recreati...</td>\n",
       "      <td>392 asser levy pl, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>http://www.nycgovparks.org/facilities/recreati...</td>\n",
       "      <td>430 W 25th St, New York, NY 10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gertrude Eredel</td>\n",
       "      <td>http://www.nycgovparks.org/facilities/recreati...</td>\n",
       "      <td>232 West 60th Street, ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hansborough</td>\n",
       "      <td>http://www.nycgovparks.org/facilities/recreati...</td>\n",
       "      <td>35 west 134th street, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tony Dapolito</td>\n",
       "      <td>http://www.nycgovparks.org/facilities/recreati...</td>\n",
       "      <td>1 clarkson st., NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     swimming_pool                                     website_source  \\\n",
       "0       Asser Levy  http://www.nycgovparks.org/facilities/recreati...   \n",
       "1          Chelsea  http://www.nycgovparks.org/facilities/recreati...   \n",
       "2  Gertrude Eredel  http://www.nycgovparks.org/facilities/recreati...   \n",
       "3      Hansborough  http://www.nycgovparks.org/facilities/recreati...   \n",
       "4    Tony Dapolito  http://www.nycgovparks.org/facilities/recreati...   \n",
       "\n",
       "                             address  \n",
       "0              392 asser levy pl, NY  \n",
       "1  430 W 25th St, New York, NY 10001  \n",
       "2           232 West 60th Street, ny  \n",
       "3           35 west 134th street, NY  \n",
       "4                 1 clarkson st., NY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pools = pd.read_csv('pools.csv')\n",
    "pools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poolsdict = pickle.load(open(\"poolsandcoords.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls = pools['website_source'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Asser Levy',\n",
       " 'Chelsea',\n",
       " 'Gertrude Eredel',\n",
       " 'Hansborough',\n",
       " 'Tony Dapolito',\n",
       " 'Brownsville',\n",
       " 'Metropolitan',\n",
       " 'St. Johns',\n",
       " 'Flushing Meadows Corona Park',\n",
       " 'Roy Wilkins',\n",
       " 'Saint Marys',\n",
       " 'Recreation Center 54']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poolist = pools['swimming_pool'].tolist()\n",
    "poolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check former database to be consistent with naming\n",
    "con = mdb.connect('localhost', 'root', '', 'lap_schedule')\n",
    "    \n",
    "schedule = pd.read_sql('SELECT * FROM lap_schedule_table5' , con)\n",
    "pooltable = pd.read_sql('SELECT * FROM  pool_table6'  , con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>swimming_pool</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Asser Levy</td>\n",
       "      <td>392 asser levy place, Manhattan, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>430 west 25th street, Manhattan, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Gertrude Eredel</td>\n",
       "      <td>232 west 60th street, Manhattan, ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hansborough</td>\n",
       "      <td>35 west 134th street, Manhattan NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tony Dapolito</td>\n",
       "      <td>1 clarkson street, Manhattan, NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    swimming_pool                              address\n",
       "0      0       Asser Levy  392 asser levy place, Manhattan, NY\n",
       "1      1          Chelsea  430 west 25th street, Manhattan, NY\n",
       "2      2  Gertrude Eredel  232 west 60th street, Manhattan, ny\n",
       "3      3      Hansborough   35 west 134th street, Manhattan NY\n",
       "4      4    Tony Dapolito     1 clarkson street, Manhattan, NY"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooltable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## go pool by pool and create a dataframe noting differences in website notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#start with asser_levy\n",
    "r = urllib.urlopen(urls[0]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "asserlevy = swimposting[7:]\n",
    "#make a loop that saves lap swim programs and substitutes the days of the week for the building hours which separate them\n",
    "asser_levy_sched = {}\n",
    "count = 0\n",
    "for i in asserlevy:\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        asser_levy_sched[days_of_week[count]] = []\n",
    "        count = count + 1\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        asser_levy_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['7:00 a - 9:00 a'], ['1:15 p - 3:00 p'], ['7:00 p - 9:20 p']],\n",
       " 'Monday': [['7:00 a - 9:00 a'], ['1:15 p - 3:45 p'], ['6:30 p - 9:20 p']],\n",
       " 'Saturday': [['8:00 a - 9:00 a'], ['2:15 p - 4:30 p']],\n",
       " 'Sunday': [['8:00 a - 11:00 a'], ['2:15 p - 4:30 p']],\n",
       " 'Thursday': [['7:00 a - 9:00 a'], ['1:15 p - 3:30 p'], ['6:30 p - 9:20 p']],\n",
       " 'Tuesday': [['7:00 a - 9:00 a'], ['1:15 p - 3:45 p'], ['6:30 p - 9:20 p']],\n",
       " 'Wednesday': [['7:00 a - 9:00 a'], ['1:15 p - 3:45 p'], ['6:30 p - 9:20 p']]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asser_levy_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#i can pickle this\n",
    "pickle.dump( asser_levy_sched, open(\"asser_levy_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now on to chelsea\n",
    "r = urllib.urlopen(urls[1]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#laps are denoted as Lap Swim on the chelsea page\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chelsea = swimposting[7:-7] #sometimes more building hours after swim schedule\n",
    "#make a loop that saves lap swim programs and substitutes the days of the week for the building hours which separate them\n",
    "chelsea_sched = {}\n",
    "count = 0\n",
    "\n",
    "for i in chelsea:\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        chelsea_sched[days_of_week[count]] = []\n",
    "        count = count + 1\n",
    "    if str(i).find('Lap Swim') > 0:\n",
    "        chelsea_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['7:00 a - 9:30 a'], ['2:00 p - 3:45 p'], ['9:00 p - 10:00 p']],\n",
       " 'Monday': [['7:00 a - 10:00 a'], ['2:00 p - 3:45 p'], ['9:00 p - 10:00 p']],\n",
       " 'Saturday': [['7:00 a - 8:00 a']],\n",
       " 'Sunday': [['8:00 a - 11:00 a'], ['3:00 p - 4:00 p']],\n",
       " 'Thursday': [['7:00 a - 10:00 a'],\n",
       "  ['1:00 p - 3:45 p'],\n",
       "  ['6:00 p - 7:00 p'],\n",
       "  ['9:00 p - 10:00 p']],\n",
       " 'Tuesday': [['7:00 a - 10:00 a'], ['1:00 p - 3:45 p'], ['6:00 p - 7:00 p']],\n",
       " 'Wednesday': [['7:00 a - 9:30 a'], ['2:00 p - 3:45 p'], ['9:00 p - 10:00 p']]}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chelsea_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i can pickle this\n",
    "pickle.dump( chelsea_sched, open(\"chelsea_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#next pool is gertrude eredel which denotes laps as Lap Swim\n",
    "r = urllib.urlopen(urls[2]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "\n",
    "gertrude = swimposting[7:-7] \n",
    "gertrude_sched = {}\n",
    "count = 0\n",
    "for i in gertrude:\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        gertrude_sched[days_of_week[count]] = []\n",
    "        count = count + 1\n",
    "    if str(i).find('Lap Swim') > 0:\n",
    "        gertrude_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['7:00 a - 9:45 a'], ['1:00 p - 3:45 p'], ['7:15 p - 9:00 p']],\n",
       " 'Monday': [['7:00 a - 9:45 a'], ['6:15 p - 9:00 p']],\n",
       " 'Saturday': [['8:00 a - 9:45 a']],\n",
       " 'Sunday': [],\n",
       " 'Thursday': [['7:00 a - 9:45 a'], ['12:00 p - 2:00 p'], ['7:15 p - 9:00 p']],\n",
       " 'Tuesday': [['7:00 a - 9:45 a'], ['12:00 p - 2:00 p'], ['6:15 p - 9:00 p']],\n",
       " 'Wednesday': [['7:00 a - 9:45 a'], ['6:15 p - 9:00 p']]}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gertrude_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i can pickle this\n",
    "pickle.dump( gertrude_sched, open(\"gertrude_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#on to hansborough which denotes as Adult Lap Swim\n",
    "r = urllib.urlopen(urls[3]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "\n",
    "hansborough = swimposting[7:-7] \n",
    "hansborough_sched = {}\n",
    "count = 0\n",
    "for i in hansborough:\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        hansborough_sched[days_of_week[count]] = []\n",
    "        count = count + 1\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        hansborough_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['7:00 a - 8:45 a'], ['3:00 p - 4:15 p'], ['7:15 p - 9:00 p']],\n",
       " 'Monday': [['7:00 a - 8:45 a'], ['1:00 p - 3:00 p'], ['7:15 p - 9:00 p']],\n",
       " 'Saturday': [['9:00 a - 10:15 a'], ['3:00 p - 4:00 p']],\n",
       " 'Sunday': [],\n",
       " 'Thursday': [['9:00 a - 10:00 a'], ['1:15 p - 3:45 p'], ['7:15 p - 9:00 p']],\n",
       " 'Tuesday': [['9:00 a - 10:00 a'], ['1:15 p - 3:45 p'], ['7:15 p - 9:00 p']],\n",
       " 'Wednesday': [['7:00 a - 8:45 a'], ['2:00 p - 3:00 p'], ['7:15 p - 9:00 p']]}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hansborough_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#i can pickle this\n",
    "pickle.dump( hansborough_sched, open(\"hansborough_sched.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#on to tony dapolito denotes by Adult Lap Swim\n",
    "r = urllib.urlopen(urls[4]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "tony_dapolito = swimposting[7:-7]\n",
    "#make a loop that saves lap swim programs and substitutes the days of the week for the building hours which separate them\n",
    "tony_dapolito_sched = {}\n",
    "count = 0\n",
    "for i in tony_dapolito:\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        tony_dapolito_sched[days_of_week[count]] = []\n",
    "        count = count + 1\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        tony_dapolito_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['7:00 a - 9:30 a'], ['11:30 a - 2:15 p'], ['5:00 p - 7:15 p']],\n",
       " 'Monday': [['7:00 a - 9:30 a'], ['11:30 a - 2:15 p'], ['4:00 p - 9:30 p']],\n",
       " 'Saturday': [['3:15 p - 4:30 p']],\n",
       " 'Sunday': [['9:00 a - 10:30 a'], ['3:15 p - 4:30 p']],\n",
       " 'Thursday': [['7:00 a - 8:30 a'], ['12:15 p - 2:15 p'], ['8:00 p - 9:30 p']],\n",
       " 'Tuesday': [['7:00 a - 8:30 a'], ['12:15 p - 2:15 p'], ['8:00 p - 9:30 p']],\n",
       " 'Wednesday': [['7:00 a - 9:30 a'],\n",
       "  ['11:30 a - 2:15 p'],\n",
       "  ['4:00 p - 6:00 p'],\n",
       "  ['7:15 p - 9:30 p']]}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tony_dapolito_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i can pickle this\n",
    "pickle.dump( tony_dapolito_sched, open(\"tony_dapolito_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#poolsched = ['Browsnvillesched', 'Metropolitansched' , 'St_Johnssched','Recreation_Center_54sched']\n",
    "#poolsadultnum = [5,6, 7, 11 ]\n",
    "r = urllib.urlopen(urls[5]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "\n",
    "brownsville = swimposting[7:-7] \n",
    "brownsville_sched = {}\n",
    "count = 0\n",
    "for i in brownsville:\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        brownsville_sched[days_of_week[count]] = []\n",
    "        count = count + 1\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        brownsville_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n",
    "pickle.dump( brownsville_sched, open(\"brownsville_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['2:15 p - 3:00 p'], ['5:15 p - 7:00 p']],\n",
       " 'Monday': [['2:15 p - 3:00 p'], ['5:15 p - 7:00 p']],\n",
       " 'Saturday': [],\n",
       " 'Sunday': [],\n",
       " 'Thursday': [],\n",
       " 'Tuesday': [],\n",
       " 'Wednesday': [['2:15 p - 3:00 p'], ['5:15 p - 7:00 p']]}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brownsville_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AHHHHHH there are scraping issues, pool hours in the dataframe below are not correct. retry metropolitan\n",
    "r = urllib.urlopen(urls[6]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other )\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "\n",
    "metropolitan = swimposting[7:]\n",
    "metropolitan_sched = {}\n",
    "count = 0\n",
    "for i in metropolitan:\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        metropolitan_sched[days_of_week[count]] = []\n",
    "        count = count + 1\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        metropolitan_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump( metropolitan_sched, open(\"metropolitan_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#poolsched = ['Browsnvillesched', 'Metropolitansched' , 'St_Johnssched','Recreation_Center_54sched']\n",
    "#poolsadultnum = [5,6, 7, 11 ]\n",
    "r = urllib.urlopen(urls[7]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "\n",
    "stjohns = swimposting[7:] \n",
    "stjohns_sched = {}\n",
    "count = 0\n",
    "for i in stjohns:\n",
    "    if count ==7:\n",
    "        break\n",
    "    else:\n",
    "        if str(i).find('Building Hours') > 0:\n",
    "            stjohns_sched[days_of_week[count]] = []\n",
    "            count = count + 1\n",
    "        if str(i).find('Adult Lap Swim') > 0:\n",
    "            stjohns_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n",
    "pickle.dump( stjohns_sched, open(\"stjohns_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.nycgovparks.org/facilities/recreationcenters/B245/schedule#Pool'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-38b36b3a25b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building Hours'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mreccenter54_sched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdays_of_week\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adult Lap Swim'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#poolsched = ['Browsnvillesched', 'Metropolitansched' , 'St_Johnssched','Recreation_Center_54sched']\n",
    "#poolsadultnum = [5,6, 7, 11 ]\n",
    "r = urllib.urlopen(urls[11]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "\n",
    "reccenter54 = swimposting[7:] \n",
    "reccenter54_sched = {}\n",
    "count = 0\n",
    "for i in reccenter54:\n",
    "    if count == 8:\n",
    "        break\n",
    "    else:\n",
    "        if str(i).find('Building Hours') > 0:\n",
    "            reccenter54_sched[days_of_week[count]] = []\n",
    "            count = count + 1\n",
    "        if str(i).find('Adult Lap Swim') > 0:\n",
    "            reccenter54_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n",
    "pickle.dump( reccenter54_sched, open(\"reccenter54_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['7:00 a - 9:45 a'], ['12:15 p - 3:00 p'], ['7:15 p - 9:00 p']],\n",
       " 'Monday': [['7:00 a - 9:45 a'], ['12:15 p - 3:00 p'], ['7:15 p - 9:00 p']],\n",
       " 'Saturday': [['8:00 a - 10:15 a']],\n",
       " 'Sunday': [],\n",
       " 'Thursday': [['7:00 a - 9:45 a'], ['12:15 p - 3:00 p'], ['7:45 p - 9:00 p']],\n",
       " 'Tuesday': [['7:00 a - 9:45 a'], ['12:15 p - 3:00 p'], ['7:45 p - 9:00 p']],\n",
       " 'Wednesday': [['7:00 a - 9:45 a'], ['12:15 p - 3:00 p'], ['7:15 p - 9:00 p']]}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reccenter54_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make a loop for all pools with same denotation of Adult Lap Swim this isn't correct yet\n",
    "poolsadult = ['Browsnville', 'Metropolitan' , 'St_Johns','Recreation_Center_54']\n",
    "poolsadultdict = ['Browsnville', 'Metropolitan' , 'St_Johns','Recreation_Center_54']\n",
    "poolsched = ['Browsnvillesched', 'Metropolitansched' , 'St_Johnssched','Recreation_Center_54sched']\n",
    "poolsched2 = ['Browsnvillesched', 'Metropolitansched' , 'St_Johnssched','Recreation_Center_54sched']\n",
    "poolsadultnum = [5,6, 7, 11 ]\n",
    "\n",
    "pickle.dump( h, open(\"%s.p\" %(poolsched2[counter]), \"wb\" ) )\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#8, Flushing Meadows Corona Park is just Lap Swim\n",
    "#9, Roy Wilkins is Adult and Senior Swim\n",
    "#10, Saint Marys is Adult Swim\n",
    "\n",
    "r = urllib.urlopen(urls[8]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Lap Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "flushing = swimposting[7:] \n",
    "flushing_sched = {}\n",
    "count = 0\n",
    "for i in flushing:\n",
    "    if count == 8:\n",
    "        break\n",
    "    else:\n",
    "        if str(i).find('Building Hours') > 0:\n",
    "            flushing_sched[days_of_week[count]] = []\n",
    "            count = count + 1\n",
    "        if str(i).find('Lap Swim') > 0:\n",
    "            flushing_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n",
    "pickle.dump( flushing_sched, open(\"flushing_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['6:00 a - 9:30 p']],\n",
       " 'Monday': [['6:00 a - 9:30 p']],\n",
       " 'Saturday': [['9:00 a - 9:30 p']],\n",
       " 'Sunday': [['9:00 a - 7:30 p']],\n",
       " 'Thursday': [['6:00 a - 9:30 p']],\n",
       " 'Tuesday': [['6:00 a - 9:30 p']],\n",
       " 'Wednesday': [['6:00 a - 9:30 p']]}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flushing_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#8, Flushing Meadows Corona Park is just Lap Swim\n",
    "#9, Roy Wilkins is Adult and Senior Swim\n",
    "#10, Saint Marys is Adult Swim\n",
    "\n",
    "r = urllib.urlopen(urls[9]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult and Senior Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "\n",
    "roywilkins = swimposting[7:] \n",
    "roywilkins_sched = {}\n",
    "count = 0\n",
    "for i in roywilkins:\n",
    "    if count == 8:\n",
    "        break\n",
    "    else:\n",
    "        if str(i).find('Building Hours') > 0:\n",
    "            roywilkins_sched[days_of_week[count]] = []\n",
    "            count = count + 1\n",
    "        if str(i).find('Adult and Senior Swim') > 0:\n",
    "            roywilkins_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n",
    "\n",
    "            \n",
    "pickle.dump( roywilkins_sched, open(\"roywilkins_sched.p\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Friday': [['8:00 a - 9:30 a'], ['5:30 p - 8:30 p']],\n",
       " 'Monday': [['8:00 a - 9:30 a'], ['6:00 p - 8:30 p']],\n",
       " 'Saturday': [],\n",
       " 'Sunday': [],\n",
       " 'Thursday': [['8:00 a - 9:30 a'], ['7:00 p - 8:30 p']],\n",
       " 'Tuesday': [['8:00 a - 9:30 a'], ['7:00 p - 8:30 p']],\n",
       " 'Wednesday': [['8:00 a - 9:30 a']]}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roywilkins_sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#8, Flushing Meadows Corona Park is just Lap Swim\n",
    "#9, Roy Wilkins is Adult and Senior Swim\n",
    "#10, Saint Marys is Adult Swim\n",
    "\n",
    "r = urllib.urlopen(urls[10]).read()\n",
    "soup = BeautifulSoup(r, \"lxml\")\n",
    "other = [\"program\", \"center-hrs\"]\n",
    "letters = soup.find_all([\"p\", \"div\"], other ) \n",
    "\n",
    "swimposting = []\n",
    "otherposting = []\n",
    "for i in letters:\n",
    "    if str(i).find('Adult Swim') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    if str(i).find('Building Hours') > 0:\n",
    "        swimposting.append(str(i))\n",
    "    else:\n",
    "        otherposting.append(str(i))\n",
    "saintmarys = swimposting[7:] \n",
    "saintmarys_sched = {}\n",
    "count = 0\n",
    "for i in saintmarys:\n",
    "    if count == 7:\n",
    "        break\n",
    "    else:\n",
    "        if str(i).find('Building Hours') > 0:\n",
    "            saintmarys_sched[days_of_week[count]] = []\n",
    "            count = count + 1\n",
    "        if str(i).find('Adult Swim') > 0:\n",
    "            saintmarys_sched[days_of_week[count-1]].append(re.findall('[0-9]*:[0-9]*\\s[a-z]\\s-\\s[0-9]*:[0-9]*\\s[a-z]'  ,str(i)))\n",
    "pickle.dump( saintmarys_sched, open(\"saintmarys_sched.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "asser_levy_sched.p\n",
      "brownsville_sched.p\n",
      "chelsea_sched.p\n",
      "flushing_sched.p\n",
      "gertrude_sched.p\n",
      "hansborough_sched.p\n",
      "metropolitan_sched.p\n",
      "reccenter54_sched.p\n",
      "roywilkins_sched.p\n",
      "saintmarys_sched.p\n",
      "stjohns_sched.p\n",
      "tony_dapolito_sched.p\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "folder = os.path.join('//', 'Users', 'cedarwaxwing', 'data_projects', '4.11.16findmypool', 'pickles_of_schedule')\n",
    "for filename in os.listdir (folder):\n",
    "    print filename\n",
    "#try to make a loop to iterate through and turn each into a dataframe\n",
    "tempnames =['Asser_Levy', 'Brownsville', 'Chelsea', 'Flushing_Meadows_Corona_Park', 'Gertrude_Eredel', 'Hansborough', 'Metropolitan',\n",
    "              'Recreation_Center_54', 'Roy_Wilkins', 'Saint_Marys', 'St._Johns', 'Tony_Dapolito']\n",
    "officalname = ['Asser Levy', 'Brownsville', 'Chelsea', 'Flushing Meadows Corona Park', 'Gertrude Eredel', 'Hansborough', 'Metropolitan',\n",
    "              'Recreation Center 54', 'Roy Wilkins', 'Saint Marys', 'St. Johns', 'Tony Dapolito']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#brownsville = pickle.load(open(\"pickles_of_schedule/brownsville_sched.p\", \"rb\"))\n",
    "officalname = ['Asser Levy', 'Brownsville', 'Chelsea', 'Flushing Meadows Corona Park', 'Gertrude Eredel', 'Hansborough', 'Metropolitan','Recreation Center 54', 'Roy Wilkins', 'Saint Marys', 'St. Johns', 'Tony Dapolito']\n",
    "\n",
    "df = pd.DataFrame()  \n",
    "for j, filename in enumerate(os.listdir (folder)):\n",
    "    pool = filename[:-8]\n",
    "    \n",
    "    pool = pickle.load(open(\"pickles_of_schedule/\" + filename, \"rb\"))\n",
    "    #print pool\n",
    "    pool = pd.DataFrame.from_dict(pool, orient='index')\n",
    "    #print pool\n",
    "    pool = pool.transpose()\n",
    "    pool['Pool'] = officalname[j]\n",
    "    #print pool\n",
    "    df = df.append(pool)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df\n",
    "pickle.dump( df, open(\"pooldataframedraft.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#allpools['Monday'].iloc[1][0] removing list containing times, just want the times\n",
    "f = lambda x: 'None' if x==None else x[0]\n",
    "df['Monday']= df['Monday'].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Tuesday'] = df['Tuesday'].map(f)\n",
    "df['Wednesday'] = df['Wednesday'].map(f)\n",
    "df['Thursday'] = df['Thursday'].map(f)\n",
    "df['Friday'] = df['Friday'].map(f)\n",
    "df['Saturday'] = df['Saturday'].map(f)\n",
    "df['Sunday'] = df['Sunday'].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump( df, open(\"pooldataframedraft.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('pooldatafinalgood.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con = mdb.connect('localhost', 'root', '', 'lap_schedule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = mdb.connect('localhost', 'root', '', 'lap_schedule') \n",
    "#pooldb = df.to_sql('lap_schedule_table5', con, flavor='mysql')\n",
    "pooldata = pd.read_sql('SELECT * FROM lap_schedule_table5', con)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7:00 a - 9:00 a</td>\n",
       "      <td>7:00 a - 9:00 a</td>\n",
       "      <td>7:00 a - 9:00 a</td>\n",
       "      <td>7:00 a - 9:00 a</td>\n",
       "      <td>7:00 a - 9:00 a</td>\n",
       "      <td>8:00 a - 11:00 a</td>\n",
       "      <td>8:00 a - 9:00 a</td>\n",
       "      <td>Asser Levy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:15 p - 3:45 p</td>\n",
       "      <td>1:15 p - 3:45 p</td>\n",
       "      <td>1:15 p - 3:00 p</td>\n",
       "      <td>1:15 p - 3:45 p</td>\n",
       "      <td>1:15 p - 3:30 p</td>\n",
       "      <td>2:15 p - 4:30 p</td>\n",
       "      <td>2:15 p - 4:30 p</td>\n",
       "      <td>Asser Levy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6:30 p - 9:20 p</td>\n",
       "      <td>6:30 p - 9:20 p</td>\n",
       "      <td>7:00 p - 9:20 p</td>\n",
       "      <td>6:30 p - 9:20 p</td>\n",
       "      <td>6:30 p - 9:20 p</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Asser Levy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2:15 p - 3:00 p</td>\n",
       "      <td>None</td>\n",
       "      <td>2:15 p - 3:00 p</td>\n",
       "      <td>2:15 p - 3:00 p</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brownsville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5:15 p - 7:00 p</td>\n",
       "      <td>None</td>\n",
       "      <td>5:15 p - 7:00 p</td>\n",
       "      <td>5:15 p - 7:00 p</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Brownsville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Monday          Tuesday           Friday        Wednesday  \\\n",
       "0  7:00 a - 9:00 a  7:00 a - 9:00 a  7:00 a - 9:00 a  7:00 a - 9:00 a   \n",
       "1  1:15 p - 3:45 p  1:15 p - 3:45 p  1:15 p - 3:00 p  1:15 p - 3:45 p   \n",
       "2  6:30 p - 9:20 p  6:30 p - 9:20 p  7:00 p - 9:20 p  6:30 p - 9:20 p   \n",
       "0  2:15 p - 3:00 p             None  2:15 p - 3:00 p  2:15 p - 3:00 p   \n",
       "1  5:15 p - 7:00 p             None  5:15 p - 7:00 p  5:15 p - 7:00 p   \n",
       "\n",
       "          Thursday            Sunday         Saturday         Pool  \n",
       "0  7:00 a - 9:00 a  8:00 a - 11:00 a  8:00 a - 9:00 a   Asser Levy  \n",
       "1  1:15 p - 3:30 p   2:15 p - 4:30 p  2:15 p - 4:30 p   Asser Levy  \n",
       "2  6:30 p - 9:20 p              None             None   Asser Levy  \n",
       "0             None              None             None  Brownsville  \n",
       "1             None              None             None  Brownsville  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
